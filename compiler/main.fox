
import "compiler/token";
import "compiler/ast";
import "compiler/parser";
import "io";

main :: func()
{
	oParser: var = Parser();

	// Read the file content
	file: var = io.open("lexer_number.fox", "r");
	content: var = file.read();
	file.close();
	
	// Setup the Lexer
	oParser.Define("WS", "[ \n\t\r]+", true);
	oParser.Define(IDENTIFIER, "[a-zA-Z_]+[0-9]*", false);
	oParser.Define(NUMBER, "[0-9]+", false);
	oParser.Define(PLUS, "\+", false);
	oParser.Define(MINUS, "-", false);
	oParser.Define(STAR, "\*", false);
	oParser.Define(SLASH, "/", false);
	oParser.Define(LEFT_PAREN, "(", false);
	oParser.Define(RIGHT_PAREN, ")", false);

	// Process the file content
	ast: var = oParser.GenAst(content);

	for (i: var = 0; i < ast.size(); i = i + 1)
	{
		print "%\n", ast.get(i).value;
	}

	// Show the tokens
	// oParser.Dump();

	// Free the memory of the Lexer
	oParser.m_oLexer.deinit();
}

main();